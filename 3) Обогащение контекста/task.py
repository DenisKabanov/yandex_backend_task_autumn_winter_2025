def main():
    with open("input.txt", 'r') as input_file, open("output.txt", 'w') as output_file: # открываем файлы для чтения и записи
        lines = input_file.read().splitlines()
        # идея: идём по запросам, берём уникальные слова из него с помощью set
        # идём по уникальным словам в запросе и если оно встречается в первый раз, то запоминаем место его первой встречи в word_to_id
        # если же данное слово уже встречалось, то необходимо старый запрос объединить с текущим рассматриваемым (так можно за раз объединить несколько запросов с последниим рассмотренным)
        # при это нужно пройтись по словам старых объединяемых запросов и переназначить id соответствующего им запроса на рассматриваемый
        # если же все слова в рассматриваемом запросе встретились впервые — добавляем запрос в словарь запросов queries (по ключу-номеру этого запроса)
        # обобщив, рассматриваем запросы по очереди, если запрос состоит из только "новых" слов, то добавляем его в queries и все встреченые в нём слова в word_to_id
        # если же в запросе есть уже встреченные слова, то старые запросы объединяем с текущим (комбинируем в один запрос)

        # берём значения из строк через split (получая list) и приводим их к типу int через map функции
        N = int(lines[0])
        queries = {} # словарь "номер:комбинированный запрос"
        word_to_id = {} # словарь соответствия слова его последней встрече среди запросов
        max_querie_concat_len = 0 # длина максимального запроса
        for i in range(2, 2*N + 1, 2): # идём по номерам строк в input (они же будут id_шниками запросов в queries и word_to_id)
            querie = set(lines[i].split()) # уникальные слова в запросе
            queries_to_concatenate = set() # список id_шников запросов в queries, которые нужно объединить с текущим запросом

            for word in querie: # идём по словам в запросе
                if word not in word_to_id: # если встретили новое слово — запоминаем номер запроса с ним
                    word_to_id[word] = i
                else: # если слово уже встречалось ранее, то запросы нужно будет объединить
                    queries_to_concatenate.add(word_to_id[word])

            queries[i] = querie # записываем текущий запрос
            for querie_id in queries_to_concatenate: # объединяем все предыдущие запросы, у которых было совпадение с текущим
                old_querie = queries[querie_id]
                for word in old_querie: # старые позиции встречи слов переписываем на новый запрос
                    word_to_id[word] = i
                
                queries[i].update(old_querie) # добавляем слова из старого запроса в новый
                del queries[querie_id] # удаляем старый совпавший запрос

            if len(queries[i]) > max_querie_concat_len: # проверяем длину нового добавленного (и, возможно, объединённого) запроса
                max_querie_concat_len = len(queries[i])

        print(f"{len(queries)} {max_querie_concat_len}", file=output_file) # делаем запись в файл


if __name__ == '__main__': # запускаем выполнение при прямом вызове скрипта (игнорируем при импорте этого файла в другой модуль)
    main()